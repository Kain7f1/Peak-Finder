{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1105e7f1-6375-4d04-b4d8-8a1dcffc9e50",
   "metadata": {},
   "source": [
    "# 4. 토큰화 Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b5fe75-a87e-42c5-b6d6-9ee6b0746f45",
   "metadata": {},
   "source": [
    "## 4-a. 토큰화 계획\n",
    "- word extraction 한 단어 리스트로 사용자 정의 사전을 만든다\n",
    "- mecab 이용하여 tokenizing 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d120c06-e484-46ce-93f1-e8e52dee342a",
   "metadata": {},
   "source": [
    "## 4-b. 토큰화 프로세스\n",
    "1. mecab 을 컴파일하고, 테스트한다\n",
    "  - 테스트할 text 를 제작한다\n",
    "  - 토큰화 테스트\n",
    "2. word extraction의 결과 단어 리스트를 불러온다\n",
    "3. 사용자 정의 사전을 제작하고, .csv 파일로 저장해둔다\n",
    "  - 종성이 있는지 판단한다\n",
    "4. 여기까지 함수화한다 (단어 리스트 불러오기 + 사용자 정의 사전 파일로 저장)\n",
    "5. 사용자 정의 사전을 `C:\\mecab\\user-dic` 에 옮긴다\n",
    "6. 사용자 정의 사전을 컴파일한다\n",
    "7. 토큰화 한다\n",
    "  - [1-a] 의 text로 테스트를 진행한다\n",
    "  - 변화가 있는지 체크한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2de9d9-d3f6-4783-98a9-385cd3126565",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4-c. 사용자 정의사전 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55384270-28cf-45f5-bb35-f98abfeacc5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4-c-1. mecab 컴파일\n",
    "- Mecab 메뉴얼 : https://kain7f1.notion.site/Mecab-195acbade3f14463b137c4490baebc76?pvs=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ae81a-4235-4d30-b870-5c9c8e572a88",
   "metadata": {},
   "source": [
    "### 4-c-2. (pycharm으로 실행) macab 토큰화 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cdbafd7-3a7b-4fc3-b5fe-51d04a64e836",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MeCab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMeCab\u001b[39;00m\n\u001b[0;32m      3\u001b[0m txt1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[특징주]자이글, 300억 유상증자 소식에 8\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m↑\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m txt2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m브이티지엠피 주가 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m신바람\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...2차전지 사업 대박 기대 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m솔솔\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'MeCab'"
     ]
    }
   ],
   "source": [
    "# 메뉴얼에 따라 빌드하고, pycharm에서 테스트합니다\n",
    "import MeCab\n",
    "\n",
    "txt1 = \"주식으로 선거때마다 한탕 해처먹는 간잽이진짜 확망했으면\"\n",
    "m = MeCab.Tagger()\n",
    "tokens = m.parse(txt1)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c12a1-4154-47f1-998d-4da5d915d997",
   "metadata": {},
   "source": [
    "### 4-c-3. word extraction의 결과 단어 리스트를 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b42de52-e67f-49ff-a23b-2e2de509b98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['엄청', '질문', '누구', '월에', '나도', '된다', '몰빵', '까지', '떡락', '지금', '등등', '학교', '미래', '구성', '팔아', '그래', '발표', '라는', '책임', '똑같', '리더', '반대', '영향', '뛰어', '다음', 'ㅅㅂ', '관련', '발행', '기사', '결정', '어떤', '저거', '경우', '선언', '본다', '올해', '지난', '애들', 'ㅇㅇ', '같이', '삼전', '국힘', '외국', '에서', '크게', '먼저', '포기', '팩트', '투자', '보수', '최소', '고점', '최대', '단타', '제발', '몰라', 'ㄷㄷ', '너무', '수도', '대표', '먹고', '요즘', '여러', '미친', '당선', '철수', '역시', '작년', '세계', '연락', '감사', '신고', '차트', '경영', '확인', '중국', '존버', '졸업', '느낌', '준비', '정치', '총선', '만원', '시간', '개미', '언제', '미국', '원래', '가장', '직접', '이번', '우리', '하나', '이런', '추천', '호남', '직원', '셀트', '일단', 'ㅠㅠ', '부분', '의원', '상장', '국내', '백신', '방법', '본인', '젊은', '허허', '다른', '벤처', '간다', '없음', '의견', '추가', '친구', '재산', '경쟁', '지지', '좋아', '에이', '저런', '시장', '폭등', '자신', '현대', '밖에', '게임', '인간', '총리', '좋은', '일부', '그냥', '후보', '시작', '전부', '관심', '양보', '함락', '오늘', '처음', '분명', '되어', '보안', '때문', '뭐냐', '의사', '최근', '투표', '기술', '가치', '시총', '노조', '상승', '경제', '모든', '내가', '호재', '재료', '같다', '시절', '서울', '위해', '갤주', '발언', '동기', '언론', '매매', '혼자', '대선', '토론', '떡상', '많이', '결과', '성장', '따라', '손해', '모두', '존나', '의대', '입장', 'ㄹㅇ', '계속', '정도', '라고', '매도', '새끼', '바로', '주가', '어제', '공부', '북한', '박사', '예상', '어느', '최고', '씨발', '중도', '물량', '능력', '설명', '뉴스', '다시', '운동', '탈출', '좆같', '해도', '함께', '선거', '거의', '자리', '근데', '과정', '내일', '예전', '해외', '삼성', '전혀', '매수', '누가', '않을', '백지', '소리', '년전', '가지', '경기', '사람', '거래', '종목', '필요', '같은', 'ㅎㅎ', '주식', '물론', '창업', '공개', '조선', '국가', '있을', '제공', '별로', '관계', '천만', '나는', '싫어', 'ㅋㅋ', '경선', '많은', '개인', '출신', '수준', '시발', '얘기', '찰스', '억원', '이미', '걱정', '인생', '국민', '급등', '테마', '수익', '결국', 'ㅇㅈ', '말고', '원장', '성공', '프로', '보면', '동안', '손절', '바른', '고소', '부산', '분당', '물린', '당시', '제가', '행동', '한국', '미리', '아직', '니가', '조금', '상황', '무료', '세력', '잘못', '올라', '돈을', '않고', '안랩', '기업', '실제', '사실', '얼마', '예정', '찾아', '교수', '통해', '적극', '운영', '한번', '회사', '싶은', '다들', '댓글', '문제', '탄핵', '빨리', '분야', '가능', '제일', '출마', '보고', '같음', '개발', '절대', '통합', '전에', '하면', '민주', '나라', '진짜', '생각', '입문', '현재', '병신', '평가', '뭔가', '주주', '여기', '연구', '산업', '말이', '니들', '무슨', '차기', '폭락', '실적', '세상', '돌파', '완전', '없다', '판단', '판교', '중에', '단국대', '지지율', '것으로', '노무현', '제대로', '새끼들', '새누리', '간철수', '주주들', '풀매수', '코스닥', '친구들', '무조건', '그래서', '동기들', 'ㄷㄷㄷ', '민주당', '정치권', '당대표', '정치를', '얼마나', '기대감', '아무리', '아니라', '이준석', '하는데', '그렇지', '김미경', '박근혜', '홍준표', '정치적', '어떻게', '서울시', '아니고', '분위기', '경기도', '서울대', '인터뷰', '윤석열', '나오는', '아니냐', '솔직히', '있을까', '학생들', '개미들', '노동자', '아버지', '아직도', '상한가', '갑자기', '외국인', '직원들', '사실상', '코스피', '나중에', '그래도', '이렇게', '타이밍', '당연히', '하한가', '지금도', '그러나', '여기서', '대주주', '간잽이', '오르는', '그렇게', '대선주', '오히려', '테마주', '유승민', '부동산', '안철수', '이새끼', '부산고', '같은데', '철수형', '동기생', '그리고', '박원순', 'ㅠㅠㅠ', '이명박', '위해서', '오세훈', '모르는', '관련주', '있는데', '정치인', '바이오', '나오면', '그런데', '연구소', 'ㅋㅋㅋ', '문재인', '문재앙', '했는데', '안희정', '수익률', '사람들', '카카오', '컴퓨터', '지지자', '하지만', '아니다', '이재명', '어차피', '이미지', '문베충', '마지막', '하면서', '아닌가', '인터넷', '않을까', '단일화', '코로나', '가능성', '대부분', '앞으로', '가즈아', '대통령', '간재앙', '아님?', '황교안', '네이버', '스타일', '대기업', '국민들', '아니면', '이야기', '서울시장', '동기생들', '지지자들', '안철수를', '서울의대', '프로그램', '우리나라', '카이스트', '여론조사', '모릅니다', '정치테마', '써니전자', '생각하는', '국민의당', '정계은퇴', '바이러스', '국회의원', '생각하고', '대한민국', '백지신탁', '기초의학', '퍼포먼스', '퍼포먼스식', '그만두겠습', '정치테마주', '안철수연구', '안철수연구소', '그만두겠습니다']\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일을 열고 읽기\n",
    "file_path = \"3_annlab_word_list.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 줄바꿈 문자 제거\n",
    "word_list = [line.strip() for line in lines]\n",
    "\n",
    "# 결과 출력\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29b8d4f-e1ac-4f73-8e2a-8637d2e5c887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c73244-e383-404b-98b2-4942eba60333",
   "metadata": {},
   "source": [
    "### 4-c-4. 사용자 정의 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2916a622-4c47-4801-88e8-fadc4e6fddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 마지막 글자에 종성이 있는지 체크하는 함수\n",
    "def has_jongseong(char):\n",
    "    if '가' <= char <= '힣':\n",
    "        unicode_value = ord(char)\n",
    "        jongseong = (unicode_value - 0xAC00) % 28\n",
    "        return jongseong != 0\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37026429-fb99-4dbc-bfb4-d45a0d497127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_dict_annlab.csv 파일이 생성되었습니다\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = []  # 사전에 들어갈 형태로 가공해서 넣을거임\n",
    "for word in word_list:\n",
    "    if len(word) == 0:\n",
    "        continue\n",
    "    if has_jongseong(word[-1]):  # 마지막 글자에 종성이 있으면 'T' 없으면 'F'\n",
    "        jongseong = 'T'\n",
    "    else:\n",
    "        jongseong = 'F'\n",
    "    # 사전 파일인 nnp.csv에 맞는 형식으로 데이터를 세팅함\n",
    "    new_row = [word, np.nan, np.nan, 0, 'NNP', '*', jongseong, word, '*', '*', '*', '*']\n",
    "    data.append(new_row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fpath_to_save = 'user_dict_annlab.csv'\n",
    "df.to_csv(fpath_to_save, index=False, encoding=\"utf-8\", header=False)\n",
    "print(f'{fpath_to_save} 파일이 생성되었습니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a83ce-751d-4b72-8db1-cc5ab271d57d",
   "metadata": {},
   "source": [
    "### 4-c-5. 사용자 정의 사전 제작 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93520e97-e9b1-47a5-9153-7300ca52fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_user_dict(fpath_word_list, fpath_user_dict):\n",
    "    # 1. word_list 파일 읽어오기\n",
    "    print(\"[progress 1/3] word_list 파일 읽어오기\")\n",
    "    with open(fpath_word_list, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    word_list = [line.strip() for line in lines]  # 줄바꿈 문자 제거\n",
    "\n",
    "    # 단어의 마지막 글자에 종성이 있는지 체크하는 함수\n",
    "    def has_jongseong(char):\n",
    "        if '가' <= char <= '힣':\n",
    "            unicode_value = ord(char)\n",
    "            jongseong = (unicode_value - 0xAC00) % 28\n",
    "            return jongseong != 0\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # 2. mecab 사전의 형식으로 데이터 가공하기\n",
    "    print(\"[progress 2/3] mecab 사전의 형식으로 데이터 가공하기\")\n",
    "    data = []  # 사전에 들어갈 형태로 가공해서 넣을거임\n",
    "    for word in word_list:\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        if has_jongseong(word[-1]):  # 마지막 글자에 종성이 있으면 'T' 없으면 'F'\n",
    "            jongseong = 'T'\n",
    "        else:\n",
    "            jongseong = 'F'\n",
    "        # 사전 파일인 nnp.csv에 맞는 형식으로 데이터를 세팅함\n",
    "        new_row = [word, np.nan, np.nan, 0, 'NNP', '*', jongseong, word, '*', '*', '*', '*']\n",
    "        data.append(new_row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # 3. 가공한 데이터를 파일로 저장하기\n",
    "    print(\"[progress 3/3] 가공한 데이터를 파일로 저장하기\")\n",
    "    df.to_csv(fpath_user_dict, index=False, encoding=\"utf-8\", header=False)\n",
    "    print(f\"{fpath_user_dict} 파일이 생성되었습니다\")\n",
    "\n",
    "    print(\"[done]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a4146-2e1a-42df-b669-40dc775d688b",
   "metadata": {},
   "source": [
    "### 4-c-6. 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af15d552-1aa4-416e-a6a5-610b05e5be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[progress 1/3] word_list 파일 읽어오기\n",
      "[progress 2/3] mecab 사전의 형식으로 데이터 가공하기\n",
      "[progress 3/3] 가공한 데이터를 파일로 저장하기\n",
      "user_dict_annlab.csv 파일이 생성되었습니다\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "fpath_word_list = \"3_annlab_word_list.txt\"\n",
    "fpath_user_dict = \"user_dict_annlab.csv\"\n",
    "\n",
    "make_user_dict(fpath_word_list, fpath_user_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86543b86-57d1-4674-beca-194825a550db",
   "metadata": {},
   "source": [
    "## 4-d. 사용자 정의 사전 컴파일\n",
    "### 4-d-1. 사용자 정의 사전을 C:\\mecab\\user-dic 에 옮긴다\n",
    "### 4-d-2. 사용자 정의 사전을 컴파일한다 (Mecab 메뉴얼 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f794c1-4511-4485-adc3-6d38da9e3636",
   "metadata": {},
   "source": [
    "## 4-e. 토큰화 Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333fe12c-7e56-48f6-aea9-2eec7f22dec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0795e5-b8c6-42da-be6d-0246e2484f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a897763-ef67-4d3e-9439-26c77bcfad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810a823-1fc6-4381-a386-851ddcd8afc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99415e1a-2843-4a6f-ba58-08a93623d799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3378a-2b07-44fd-8ba6-4bd92e0669bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1b5a1-f4ab-4d5a-9419-4a8eb048a442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c14a8-d7f4-49a5-a01b-7460414ba790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b314f04-5511-4022-8d65-6731d0c96f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d54ff-f433-4982-9ec7-8e87f875597b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
